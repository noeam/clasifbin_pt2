{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T22:07:29.306838Z",
     "start_time": "2023-05-03T22:07:28.879375Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T22:07:31.213946Z",
     "start_time": "2023-05-03T22:07:31.177465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obesidad</th>\n",
       "      <th>ejer_act</th>\n",
       "      <th>ejer_1</th>\n",
       "      <th>ejer_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1798 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     obesidad ejer_act ejer_1 ejer_5\n",
       "0           0        M      M      B\n",
       "1           0        M      M      M\n",
       "2           0        M      M      M\n",
       "3           0        M      B      B\n",
       "4           0        B      B      B\n",
       "...       ...      ...    ...    ...\n",
       "1793        0        B      B      B\n",
       "1794        0        M      M      B\n",
       "1795        0        M      M      B\n",
       "1796        0        M      B      B\n",
       "1797        0        M      B      B\n",
       "\n",
       "[1798 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/noeam/Documents/git/github/proyecto_pt2/outputs/completo_seleccionadas.csv\")\n",
    "df = df.astype(\"category\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T22:07:59.838124Z",
     "start_time": "2023-05-03T22:07:59.830517Z"
    }
   },
   "outputs": [],
   "source": [
    "df['ejer_act'] = df['ejer_act'].replace('B',1).replace('M',0)\n",
    "df['ejer_1'] = df['ejer_1'].replace('B',1).replace('M',0)\n",
    "df['ejer_5'] = df['ejer_5'].replace('B',1).replace('M',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T22:08:05.411695Z",
     "start_time": "2023-05-03T22:08:05.400695Z"
    }
   },
   "outputs": [],
   "source": [
    "label = df['obesidad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T22:08:33.048862Z",
     "start_time": "2023-05-03T22:08:33.041863Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(['obesidad'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T22:08:43.380756Z",
     "start_time": "2023-05-03T22:08:42.789878Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T22:08:58.960522Z",
     "start_time": "2023-05-03T22:08:58.937688Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_val, label_train, label_val = train_test_split(df, label, test_size=0.20, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T22:09:06.012298Z",
     "start_time": "2023-05-03T22:09:05.989168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1438, 3), (1438,), (360, 3), (360,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, label_train.shape, X_val.shape, label_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "s = StandardScaler()\n",
    "\n",
    "X_train_scaled = s.fit_transform(X_train)\n",
    "X_val_scaled = s.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear').fit(X_train_scaled, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# L1 regularized logistic regression\n",
    "lr_l1 = LogisticRegressionCV(Cs=15, cv=4, penalty='l1', solver='liblinear').fit(X_train_scaled, label_train)  #C=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 regularized logistic regression\n",
    "lr_l2 = LogisticRegressionCV(Cs=15, cv=4, penalty='l2', solver='liblinear').fit(X_train_scaled, label_train)  #C=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lr  l1  l2\n",
       "0   0   0   0\n",
       "1   0   0   0\n",
       "2   0   0   0\n",
       "3   0   0   0\n",
       "4   0   0   0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the class and the probability for each\n",
    "y_pred = list()\n",
    "y_prob = list()\n",
    "\n",
    "coeff_labels = ['lr', 'l1', 'l2']\n",
    "coeff_models = [lr, lr_l1, lr_l2]\n",
    "\n",
    "for lab,mod in zip(coeff_labels, coeff_models):\n",
    "    y_pred.append(pd.Series(mod.predict(X_val_scaled), name=lab))\n",
    "    y_prob.append(pd.Series(mod.predict_proba(X_val_scaled).max(axis=1), name=lab))\n",
    "\n",
    "y_pred = pd.concat(y_pred, axis=1)\n",
    "y_prob = pd.concat(y_prob, axis=1)\n",
    "\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.715919</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.506305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.715919</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.506305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.715919</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.506305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.715919</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.506305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.828147</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.512975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lr   l1        l2\n",
       "0  0.715919  0.5  0.506305\n",
       "1  0.715919  0.5  0.506305\n",
       "2  0.715919  0.5  0.506305\n",
       "3  0.715919  0.5  0.506305\n",
       "4  0.828147  0.5  0.512975"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for Logistic regression without regularization:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87       278\n",
      "           1       0.00      0.00      0.00        82\n",
      "\n",
      "    accuracy                           0.77       360\n",
      "   macro avg       0.39      0.50      0.44       360\n",
      "weighted avg       0.60      0.77      0.67       360\n",
      "\n",
      "Classification report for Logistic regression with L1(Lasso) regularization:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87       278\n",
      "           1       0.00      0.00      0.00        82\n",
      "\n",
      "    accuracy                           0.77       360\n",
      "   macro avg       0.39      0.50      0.44       360\n",
      "weighted avg       0.60      0.77      0.67       360\n",
      "\n",
      "Classification report for Logistic regression with L2(Ridge) regularization:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87       278\n",
      "           1       0.00      0.00      0.00        82\n",
      "\n",
      "    accuracy                           0.77       360\n",
      "   macro avg       0.39      0.50      0.44       360\n",
      "weighted avg       0.60      0.77      0.67       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noeam\\.virtualenvs\\proyecto_pt2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\noeam\\.virtualenvs\\proyecto_pt2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\noeam\\.virtualenvs\\proyecto_pt2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\noeam\\.virtualenvs\\proyecto_pt2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\noeam\\.virtualenvs\\proyecto_pt2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\noeam\\.virtualenvs\\proyecto_pt2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\noeam\\.virtualenvs\\proyecto_pt2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\noeam\\.virtualenvs\\proyecto_pt2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\noeam\\.virtualenvs\\proyecto_pt2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print('Classification report for Logistic regression without regularization:')\n",
    "print(classification_report(label_val,y_pred['lr']))\n",
    "\n",
    "print('Classification report for Logistic regression with L1(Lasso) regularization:')\n",
    "print(classification_report(label_val,y_pred['l1']))\n",
    "\n",
    "print('Classification report for Logistic regression with L2(Ridge) regularization:')\n",
    "print(classification_report(label_val,y_pred['l2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noeam\\.virtualenvs\\proyecto_pt2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\noeam\\.virtualenvs\\proyecto_pt2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\noeam\\.virtualenvs\\proyecto_pt2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "metrics = list()\n",
    "cm = dict()\n",
    "\n",
    "for lab in coeff_labels:\n",
    "\n",
    "    # Precision, recall, f-score from the multi-class support function, we will average them because we will have one value per class\n",
    "    precision, recall, fscore, _ = score(label_val, y_pred[lab], average='weighted')\n",
    "\n",
    "    # The usual way to calculate accuracy\n",
    "    accuracy = accuracy_score(label_val, y_pred[lab])\n",
    "\n",
    "    # ROC-AUC scores can be calculated by binarizing the data\n",
    "    auc = roc_auc_score(label_binarize(label_val, classes=[0,1]),\n",
    "                        label_binarize(y_pred[lab], classes=[0,1]),\n",
    "                        average='weighted')\n",
    "\n",
    "    # Last, the confusion matrix\n",
    "    cm[lab] = confusion_matrix(label_val, y_pred[lab])\n",
    "\n",
    "    metrics.append(pd.Series({'precision':precision, 'recall':recall,\n",
    "                              'fscore':fscore, 'accuracy':accuracy,\n",
    "                              'auc':auc},\n",
    "                             name=lab))\n",
    "\n",
    "metrics = pd.concat(metrics, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.596327</td>\n",
       "      <td>0.596327</td>\n",
       "      <td>0.596327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.772222</td>\n",
       "      <td>0.772222</td>\n",
       "      <td>0.772222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fscore</th>\n",
       "      <td>0.672971</td>\n",
       "      <td>0.672971</td>\n",
       "      <td>0.672971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.772222</td>\n",
       "      <td>0.772222</td>\n",
       "      <td>0.772222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 lr        l1        l2\n",
       "precision  0.596327  0.596327  0.596327\n",
       "recall     0.772222  0.772222  0.772222\n",
       "fscore     0.672971  0.672971  0.672971\n",
       "accuracy   0.772222  0.772222  0.772222\n",
       "auc        0.500000  0.500000  0.500000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the confusion matrix for each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1,3,figsize=(18,5))\n",
    "\n",
    "disp1 = ConfusionMatrixDisplay(confusion_matrix=cm['lr'], display_labels=lr.classes_)\n",
    "disp1.plot(cmap='Blues', ax=ax1)\n",
    "ax1.set_title('Logistic')\n",
    "\n",
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=cm['l1'], display_labels=lr.classes_)\n",
    "disp2.plot(cmap='Blues', ax=ax2)\n",
    "ax2.set_title('Logistic Lasso')\n",
    "\n",
    "disp3 = ConfusionMatrixDisplay(confusion_matrix=cm['l2'], display_labels=lr.classes_)\n",
    "disp3.plot(cmap='Blues', ax=ax3)\n",
    "ax3.set_title('Logistic Ridge')\n",
    "\n",
    "#f.suptitle('Confusion matrix of models')\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(label).value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
